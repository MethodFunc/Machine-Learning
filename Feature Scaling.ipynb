{"cells":[{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Feature 들의 평균 값\nsepal length (cm)    5.843333\nsepal width (cm)     3.057333\npetal length (cm)    3.758000\npetal width (cm)     1.199333\ndtype: float64\n\nFeature 들의 분산 값\nsepal length (cm)    0.685694\nsepal width (cm)     0.189979\npetal length (cm)    3.116278\npetal width (cm)     0.581006\ndtype: float64\n"}],"source":["# <--StandardScaler-->\n","\n","iris = load_iris()\n","iris_data = iris.data\n","iris_df = pd.DataFrame(iris_data, columns=iris.feature_names)\n","print('Feature 들의 평균 값')\n","print(iris_df.mean())\n","print('\\nFeature 들의 분산 값')\n","print(iris_df.var())\n",""]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Feature 들의 평균 값\nsepal length (cm)   -1.690315e-15\nsepal width (cm)    -1.842970e-15\npetal length (cm)   -1.698641e-15\npetal width (cm)    -1.409243e-15\ndtype: float64\n\nFeature 들의 분산 값\nsepal length (cm)    1.006711\nsepal width (cm)     1.006711\npetal length (cm)    1.006711\npetal width (cm)     1.006711\ndtype: float64\n"}],"source":["# StandardScaler  객체 생성\n","\n","scaler = StandardScaler()\n","# StandardScaler로 데이터 세트 변환 .fit()과 transform()으로 호출\n","\n","scaler.fit(iris_df)\n","\n","iris_scaled = scaler.transform(iris_df)\n","# transform 시 스케일 변환된 데이터 세트가  numpy ndarray 로 반환 돼 이를  DataFrame으로 변환\n","\n","iris_df_scaled = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n","print('Feature 들의 평균 값')\n","print(iris_df_scaled.mean())\n","print('\\nFeature 들의 분산 값')\n","print(iris_df_scaled.var())\n",""]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Feature 들의 평균 값\nsepal length (cm)    0.428704\nsepal width (cm)     0.440556\npetal length (cm)    0.467458\npetal width (cm)     0.458056\ndtype: float64\n\nFeature 들의 분산 값\nsepal length (cm)    0.052908\nsepal width (cm)     0.032983\npetal length (cm)    0.089522\npetal width (cm)     0.100869\ndtype: float64\n"}],"source":["# <--MinMaxScaler-->\n","# MinMaxScaler객체 생성\n","\n","scaler = MinMaxScaler()\n","# MinMaxScaler로 데이터 세트 변환 fit()와 transform() 호출\n","\n","scaler.fit(iris_df)\n","\n","iris_scaled = scaler.transform(iris_df)\n","# transform 시 스케일 변환된 데이터 세트가  numpy ndarray 로 반환 돼 이를  DataFrame으로 변환\n","\n","iris_df_scaled = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n","print('Feature 들의 평균 값')\n","print(iris_df_scaled.mean())\n","print('\\nFeature 들의 분산 값')\n","print(iris_df_scaled.var())\n",""]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Origin train_array data:  [ 0  1  2  3  4  5  6  7  8  9 10]\nScaled train_array data:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"}],"source":["# <-- 변환 시 유의점 -->\n","''' 학습 데이터는 0브타 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n","Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원변경 '''\n","\n","train_array = np.arange(0, 11).reshape(-1, 1)\n","\n","test_array = np.arange(0, 6).reshape(-1, 1)\n","# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0-1 값으로 변환\n","\n","scalear = MinMaxScaler()\n","# fit()을 하게되면 train_array 값이 최소값 0, 최대값 10으로 설정\n","\n","scaler.fit(train_array)\n","# 1/10 scale로 train_array 데이터 변환함. 원본 10 -> 1로 변환됨\n","\n","train_scaled = scaler.transform(train_array)\n","print('Origin train_array data: ', np.round(train_array.reshape(-1), 2))\n","print('Scaled train_array data: ',  np.round(train_scaled.reshape(-1), 2))\n",""]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Origin test_array data:  [0 1 2 3 4 5]\nScaled test_array data:  [0.  0.2 0.4 0.6 0.8 1. ]\n"}],"source":["# Test data fit\n","\n","scaler.fit(test_array)\n","# 1/5 scale test_array value 5 -> 1\n","\n","test_scaled = scaler.transform(test_array)\n","# Output\n","\n","print('Origin test_array data: ', np.round(test_array.reshape(-1), 2))\n","print('Scaled test_array data: ',  np.round(test_scaled.reshape(-1), 2))\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Origin train_array data:  [ 0  1  2  3  4  5  6  7  8  9 10]\nScaled train_array data:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\nOrigin test_array data:  [0 1 2 3 4 5]\nScaled test_array data:  [0.  0.1 0.2 0.3 0.4 0.5]\n"}],"source":["# <-- 변환 시 유의점 -->\n","\n","train_array = np.arange(0, 11).reshape(-1, 1)\n","test_array = np.arange(0, 6).reshape(-1, 1)\n","scalear = MinMaxScaler()\n","scaler.fit(train_array)\n","train_scaled = scaler.transform(train_array)\n","print('Origin train_array data: ', np.round(train_array.reshape(-1), 2))\n","\n","print('Scaled train_array data: ',  np.round(train_scaled.reshape(-1), 2))\n","# fit()을 호출하지 말아야 정상적인 값으로 출력됨.\n","\n","test_scaled = scaler.transform(test_array)\n","print('Origin test_array data: ', np.round(test_array.reshape(-1), 2))\n","print('Scaled test_array data: ',  np.round(test_scaled.reshape(-1), 2))\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Origin train_array data:  [ 0  1  2  3  4  5  6  7  8  9 10]\nScaled train_array data:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\nOrigin test_array data:  [0 1 2 3 4 5]\nScaled test_array data:  [0.  0.1 0.2 0.3 0.4 0.5]\n"}],"source":["# <-- 변환 시 유의점 -->\n","\n","train_array = np.arange(0, 11).reshape(-1, 1)\n","test_array = np.arange(0, 6).reshape(-1, 1)\n","\n","scalear = MinMaxScaler()\n","# scaler.fit(train_array)\n","\n","train_scaled = scaler.fit_transform(train_array)\n","print('Origin train_array data: ', np.round(train_array.reshape(-1), 2))\n","\n","print('Scaled train_array data: ',  np.round(train_scaled.reshape(-1), 2))\n","# fit()을 호출하지 말아야 정상적인 값으로 출력됨.\n","\n","''' 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 하므로 따로 fit()을 하지 않는다.'''\n","test_scaled = scaler.transform(test_array)\n","print('Origin test_array data: ', np.round(test_array.reshape(-1), 2))\n","print('Scaled test_array data: ',  np.round(test_scaled.reshape(-1), 2))\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}